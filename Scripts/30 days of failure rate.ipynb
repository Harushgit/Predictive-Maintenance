{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72876f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3691a8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load Datasets\n",
    "dataset_train = pd.read_csv(r'C:\\Users\\njhar\\Downloads\\train_FD001.txt', sep=\" \", header=None).drop([26, 27], axis=1)\n",
    "col_names = ['id', 'cycle', 'setting1', 'setting2', 'setting3', 's1', 's2', 's3', 's4', 's5', 's6',\n",
    "             's7', 's8', 's9', 's10', 's11', 's12', 's13', 's14', 's15', 's16', 's17', 's18',\n",
    "             's19', 's20', 's21']\n",
    "dataset_train.columns = col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62b1862",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = pd.read_csv(r'C:\\Users\\njhar\\Downloads\\test_FD001.txt', sep=\" \", header=None).drop([26, 27], axis=1)\n",
    "dataset_test.columns = col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc44f428",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm_truth = pd.read_csv(r'C:\\Users\\njhar\\Downloads\\RUL_FD001.txt', sep=\" \", header=None).drop([1], axis=1)\n",
    "pm_truth.columns = ['more']\n",
    "pm_truth['id'] = pm_truth.index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364a5acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Prepare the dataset for training\n",
    "# Generate column max for test data\n",
    "rul = pd.DataFrame(dataset_test.groupby('id')['cycle'].max()).reset_index()\n",
    "rul.columns = ['id', 'max']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c49aa93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run to failure\n",
    "pm_truth['rtf'] = pm_truth['more'] + rul['max']\n",
    "pm_truth.drop('more', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f588e775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the test set with RUL\n",
    "dataset_test = dataset_test.merge(pm_truth, on=['id'], how='left')\n",
    "dataset_test['ttf'] = dataset_test['rtf'] - dataset_test['cycle']\n",
    "dataset_test.drop('rtf', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfa996b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Time to Failure (TTF) for training data\n",
    "dataset_train['ttf'] = dataset_train.groupby(['id'])['cycle'].transform(max) - dataset_train['cycle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9389ab68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create labels\n",
    "period = 30\n",
    "dataset_train['label_bc'] = dataset_train['ttf'].apply(lambda x: 1 if x <= period else 0)\n",
    "dataset_test['label_bc'] = dataset_test['ttf'].apply(lambda x: 1 if x <= period else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b469f8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature columns and target column\n",
    "features_col_name = ['setting1', 'setting2', 'setting3', 's1', 's2', 's3', 's4', 's5', 's6',\n",
    "                     's7', 's8', 's9', 's10', 's11', 's12', 's13', 's14', 's15', 's16',\n",
    "                     's17', 's18', 's19', 's20', 's21']\n",
    "target_col_name = 'label_bc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d258be22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Normalize Features\n",
    "sc = MinMaxScaler()\n",
    "dataset_train[features_col_name] = sc.fit_transform(dataset_train[features_col_name])\n",
    "dataset_test[features_col_name] = sc.transform(dataset_test[features_col_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e413d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Prepare Data for LSTM\n",
    "def gen_sequence(id_df, seq_length, seq_cols):\n",
    "    df_zeros = pd.DataFrame(np.zeros((seq_length - 1, id_df.shape[1])), columns=id_df.columns)\n",
    "    id_df = pd.concat([df_zeros, id_df], ignore_index=True)\n",
    "    data_array = id_df[seq_cols].values\n",
    "    num_elements = data_array.shape[0]\n",
    "    lstm_array = []\n",
    "    for start in range(num_elements - seq_length):\n",
    "        lstm_array.append(data_array[start:start + seq_length, :])\n",
    "    return np.array(lstm_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c680ccd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate labels\n",
    "def gen_label(id_df, seq_length, label):\n",
    "    df_zeros = pd.DataFrame(np.zeros((seq_length - 1, id_df.shape[1])), columns=id_df.columns)\n",
    "    id_df = pd.concat([df_zeros, id_df], ignore_index=True)\n",
    "    y_label = []\n",
    "    num_elements = id_df.shape[0]\n",
    "    for stop in range(seq_length, num_elements):\n",
    "        y_label.append(id_df[label].iloc[stop])\n",
    "    return np.array(y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ea90e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timestamp or window size\n",
    "seq_length = 50\n",
    "seq_cols = features_col_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c0282f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate X_train\n",
    "X_train = np.concatenate(\n",
    "    [gen_sequence(dataset_train[dataset_train['id'] == id], seq_length, seq_cols) for id in dataset_train['id'].unique()]\n",
    ")\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "\n",
    "# Generate y_train\n",
    "y_train = np.concatenate(\n",
    "    [gen_label(dataset_train[dataset_train['id'] == id], seq_length, 'label_bc') for id in dataset_train['id'].unique()]\n",
    ")\n",
    "print(\"y_train shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730aed21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate X_test\n",
    "X_test = np.concatenate(\n",
    "    [gen_sequence(dataset_test[dataset_test['id'] == id], seq_length, seq_cols) for id in dataset_test['id'].unique()]\n",
    ")\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "\n",
    "# Generate y_test\n",
    "y_test = np.concatenate(\n",
    "    [gen_label(dataset_test[dataset_test['id'] == id], seq_length, 'label_bc') for id in dataset_test['id'].unique()]\n",
    ")\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97d69f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Build and Train LSTM Model\n",
    "nb_features = X_train.shape[2]\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=100, input_shape=(seq_length, nb_features), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=50, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4182f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=200, validation_split=0.05, verbose=1,\n",
    "          callbacks=[EarlyStopping(monitor='val_loss', patience=3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b53398b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Model Evaluation\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
    "print('Accuracy of model on test data: ', accuracy_score(y_test, y_pred))\n",
    "print('-------------------------------------------------------------------')\n",
    "print('Confusion Matrix: \\n', confusion_matrix(y_test, y_pred))\n",
    "print('-------------------------------------------------------------------')\n",
    "print('Classification Report: \\n', classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b298b931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Probability of Failure Function\n",
    "def prob_failure(machine_id):\n",
    "    machine_df = dataset_test[dataset_test.id == machine_id]\n",
    "    machine_test = gen_sequence(machine_df, seq_length, seq_cols)\n",
    "    m_pred = model.predict(machine_test)\n",
    "    failure_prob = list(m_pred[-1] * 100)[0]  # Probability as a percentage\n",
    "    return failure_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6384062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Probability of failure for machine ID 16\n",
    "machine_id = int(input(\"Enter the Engine ID: \"))\n",
    "print('Probability that machine will fail within 30 days: ', prob_failure(machine_id))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
